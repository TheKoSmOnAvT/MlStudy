{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_1_students_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUuyLVDZ4s8r"
      },
      "source": [
        "## ЗАДАНИЕ ДЛЯ ПРОГРАММИРУЮЩИХ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwJ5Q6w2IFHA"
      },
      "source": [
        "**Ссылка**, на источник текста"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64uxt-07IEec"
      },
      "source": [
        "DATA_URL = \"http://az.lib.ru/t/tolstoj_a_k/text_0180.shtml\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwrBkeLnHuA1"
      },
      "source": [
        "Устанавливаем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Fr5swwYfz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfcb1721-b53f-4d1d-f48e-ec4f9f1332d3"
      },
      "source": [
        "! pip install -q PyYaml==5.3.1\n",
        "! pip install -q rnnmorph==0.4.0\n",
        "! pip install -q keras==2.1.4\n",
        "! pip install -q h5py==2.7.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 269 kB 5.2 MB/s \n",
            "\u001b[?25h  Building wheel for PyYaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 47.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 44.0 MB/s \n",
            "\u001b[?25h  Building wheel for rnnmorph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for russian-tagsets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 322 kB 5.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.1.4 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 256 kB 5.0 MB/s \n",
            "\u001b[?25h  Building wheel for h5py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires h5py>=2.9.0, but you have h5py 2.7.0 which is incompatible.\n",
            "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.1.4 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxMKqhPH1Dk"
      },
      "source": [
        "Создаём объект морфологического анализатора `RNNMorph`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24zMUhvi99AV",
        "outputId": "24edea9c-b67c-40b3-8007-4a7e10b19f91"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "predictor = RNNMorphPredictor(language=\"ru\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59q1L9p0H9K9"
      },
      "source": [
        "Скачиваем текст, по которому будет дано задание, с помощью `urllib`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uW0fw_h-Pft"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "opener = urllib.request.URLopener({})\n",
        "resource = opener.open(DATA_URL)\n",
        "raw_text = resource.read().decode(resource.headers.get_content_charset()) #Текс с html тегами"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-hSPOjDo4sdh",
        "outputId": "8e8908ec-db18-4884-c26c-e5b4a3431707"
      },
      "source": [
        "raw_text[:200]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<html>\\r\\n<head>\\r\\n<title>Lib.ru/Классика: Толстой Алексей Константинович. Семья вурдалака</title>\\r\\n</head>\\r\\n\\r\\n<body>\\r\\n\\r\\n\\r\\n<center>\\r\\n\\r\\n<h2><a href=/t/tolstoj_a_k/>Толстой Алексей Константинович</a><br>\\r\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZiLHQNSITAt"
      },
      "source": [
        "Как видно, текст содержит html теги, от которых нужно избавиться. Выбрасываем из текста HTML-теги с помощью библиотеки Beatiful soap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We4LkyUMPfuq"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(raw_text, features=\"html.parser\")\n",
        "\n",
        "# kill all script and style elements\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()    # rip it out\n",
        "\n",
        "# get text\n",
        "cleaned_text = soup.get_text()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lOD8PJnG4rbl",
        "outputId": "195f8015-85fd-4fa6-b5f3-ea242c1b54ce"
      },
      "source": [
        "cleaned_text[:200]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nLib.ru/Классика: Толстой Алексей Константинович. Семья вурдалака\\n\\n\\n\\nТолстой Алексей Константинович\\r\\nСемья вурдалака\\n\\n\\nLib.ru/Классика:\\n\\r\\n\\n\\n[Регистрация]\\n \\n\\r\\n\\r\\n\\r\\n[Найти] \\r\\n[Рейтинги]\\r\\n[Обсуждения]\\r\\n['"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = \"\"\n",
        "f = open('text.txt')\n",
        "for line in f:\n",
        "  cleaned_text += line"
      ],
      "metadata": {
        "id": "pxn-m_WSKCvC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14fYYb5hIpnY"
      },
      "source": [
        "С помощью библиотеки [NLTK](https://nltk.org/) разбиваем текст на предложения и токены."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "hRNu7jPvN6G_",
        "outputId": "2172a23d-bb3b-4510-ab01-03140793aa27"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(cleaned_text)]\n",
        "\"A total of %d 'sentences'\" % len(tokenized_sentences)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A total of 1423 'sentences'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRU4KEBAIyYT"
      },
      "source": [
        "## Задание 1\n",
        "С помощью метода `str.isalpha` из стандартной библиотеки Python модифицируйте нижеследующий код так, чтобы в predictions остались только буквенные токены."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tqdmCollection = tqdm(predictor.predict_sentences(sentences=tokenized_sentences), \"sentences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5M1jBrqh0AI",
        "outputId": "d6b5c8be-5687-4694-f19c-0574036c8eea"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsentences:   0%|          | 0/1423 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U5HH2CDPVUM",
        "outputId": "dbcddfb7-1707-4994-ffa8-72964872a877"
      },
      "source": [
        "from tqdm import tqdm\n",
        "#[pred.normal_form for pred in sent] \n",
        "predictions = []\n",
        "for sent in tqdmCollection:\n",
        "  for word in sent:\n",
        "    if word.normal_form.isalpha():\n",
        "      predictions.append(word.normal_form)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsentences: 100%|██████████| 1423/1423 [00:00<00:00, 48486.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHGDhxhNJtTz"
      },
      "source": [
        "Проверьте себя. Должны получиться следующие значения:\n",
        "\n",
        "*   Предложений: 577 (возможны расхождения в несколько предложений)\n",
        "*   Токенов: примерно 8621 (возможны расхождения в некоторое количество токенов)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwK_qRbw6sac",
        "outputId": "2c84d8ac-f79c-4648-8f4d-fffd90dabfb7"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20377"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5jL4sWyKUnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e54a0578-d7d0-44fc-ac08-74b4912e05a1"
      },
      "source": [
        "non_uniq_tokens = [word for sentence in predictions for word in sentence]\n",
        "len(non_uniq_tokens) \n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105738"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg2e-1hAKiT3"
      },
      "source": [
        "Для продолжения работы над заданием числа должны быть близки к указанным"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mci9Nd5hKuJP"
      },
      "source": [
        "## Задание 2\n",
        "\n",
        "Используя `non_uniq_tokens`, стоп-слова для русского языка из библиотеки nltk (`nltk.corpus.stopwords`) и `nltk.FreqDist`, вычислите, **какую долю среди 100 самых частотных** токенов в произведении занимают токены, **не относящиеся** к стоп словам. \n",
        "\n",
        "**Например**, если среди 100 самых частотных слов встречается 25 слов, входящих в стоп лист, значит не входят в стоп лист 75 слов, и их доля составит 0.75. \n",
        "\n",
        "**Не бойтесь использовать документацию NLTK и тьюториалы.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHbtLqkLKfZC",
        "outputId": "c3a6a86d-332d-489e-e3ca-d3fe5e5721b9"
      },
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = set(stopwords.words(\"russian\"))\n",
        "stopwords.words(\"russian\")[:5] #Пример стоп слов"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['и', 'в', 'во', 'не', 'что']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictPredict = nltk.FreqDist(predictions)\n",
        "listWordsPrediction = []\n",
        "\n",
        "count = 0\n",
        "for i,j in (dict(sorted(dictPredict.items(), key=lambda item: item[1], reverse=True))).items():\n",
        "  listWordsPrediction.append(i)\n",
        "  count+=1\n",
        "  if(count == 40):\n",
        "    break\n"
      ],
      "metadata": {
        "id": "REfa89H35s6d"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for word in listWordsPrediction:\n",
        "  if(word in STOPWORDS):\n",
        "    count+=1\n",
        "count/100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QztclSNaBhzt",
        "outputId": "c27c436a-1042-4b8b-b4b9-0e3b49007b1b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezdbB95YwtSl"
      },
      "source": [
        "Проверьте себя: должно получиться 0.49 (допустимо небольшое расхождение)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HChyAdk2Ovx1"
      },
      "source": [
        "## Задание 3\n",
        "Вычислите, сколько токенов встречается в тексте **строго больше** 50 раз."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cc = 0\n",
        "for  key,value in dict(sorted(dictPredict.items(), key=lambda item: item[1], reverse=True)).items():\n",
        "  if value < 21:\n",
        "    break\n",
        "  cc+=1\n",
        "\n"
      ],
      "metadata": {
        "id": "7GYKbzit5ksP"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42SSSyZVCpZi",
        "outputId": "10b23f52-a8ff-4eed-e060-91df7bb54212"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6HZ2w3yxJEh"
      },
      "source": [
        "Проверьте себя: должно получиться значение 22 (возможно небольшое расхождение)\n"
      ]
    }
  ]
}